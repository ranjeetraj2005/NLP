{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PosTaggingFlair.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjeetraj2005/NLP/blob/master/PosTaggingFlair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "X-fpP9CmV--9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "596352f5-e566-4d03-c7d8-f08f3de6e686"
      },
      "cell_type": "code",
      "source": [
        "### file was uploaded manually to local environment of Colab ###\n",
        "data = open('pos-tagged_corpus.txt','r')\n",
        "txt = data.read()\n",
        "#print(txt)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c3881f147895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pos-tagged_corpus.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(txt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pos-tagged_corpus.txt'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "aAJClMmCWdpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "d6d7b86d-25a8-4f46-de17-4e8e0a977b96"
      },
      "cell_type": "code",
      "source": [
        "### converting text in form of list of (words with their tags) ###\n",
        "txt = txt.split('\\n')\n",
        "\n",
        "### removing DOCSTART (document header)\n",
        "txt = [x for x in txt if x != '-DOCSTART- -X- -X- O']\n",
        "### check ###\n",
        "for i in range(10):\n",
        "  print(txt[i])\n",
        "  print(‘-’*10)\n",
        "\n",
        "### Extracting Sentences ###\n",
        "# Initialize empty list for storing words\n",
        "words = []\n",
        "# initialize empty list for storing sentences #\n",
        "corpus = []\n",
        "\n",
        "for i in tqdm(txt):\n",
        "  ## if blank sentence encountered ##\n",
        "  if i =='':\n",
        "    ## previous words form a sentence ##\n",
        "    corpus.append(' '.join(words))\n",
        "    ## Refresh Word list ##\n",
        "    words = []\n",
        "  else:\n",
        "   ## word at index 0 ##\n",
        "    words.append(i.split()[0])\n",
        "  \n",
        "# did it work? #\n",
        "for i in range(10):\n",
        "  print(corpus[i])\n",
        "  print(‘-’*10)\n",
        "\n",
        "\n",
        "### Extracting POS ###\n",
        "# Initialize empty list for storing word pos\n",
        "w_pos = []\n",
        "#initialize empty list for storing sentence pos #\n",
        "POS = []\n",
        "for i in tqdm(txt):\n",
        "  ## blank sentence = new line ##\n",
        "  if i =='':\n",
        "    ## previous words form a sentence POS ##\n",
        "    POS.append(' '.join(w_pos))\n",
        "    ## Refresh words list ##\n",
        "    w_pos = []\n",
        "  else:\n",
        "    ## pos tag from index 1 ##\n",
        "    w_pos.append(i.split()[1])\n",
        "  \n",
        "# did it work? #\n",
        "for i in range(10):\n",
        "  print(corpus[i])\n",
        "  print(POS[i])\n",
        "\n",
        "### Removing blanks form sentence and pos ###\n",
        "corpus = [x for x in corpus if x!= '']\n",
        "POS = [x for x in POS if x!= '']\n",
        "\n",
        "### Check ###\n",
        "For i in range(10):\n",
        "  print(corpus[i])\n",
        "  print(POS[i])\n",
        "\n",
        "import nltk\n",
        "nltk.download('tagsets')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import word_tokenize"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-8c6a60db30b7>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    print(‘-’*10)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "E3nCYodPW8rv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6YbTUAN6Whrt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "155cb8d1-545f-422e-c7ad-46b84ca988b3"
      },
      "cell_type": "code",
      "source": [
        "### Tagging the corpus with NLTK ###\n",
        "#for storing results#\n",
        "nltk_pos = []\n",
        "##for every sentence ##\n",
        "for i in tqdm(corpus):\n",
        "  # Tokenize sentence #\n",
        "  text = word_tokenize(i)\n",
        "  #tag Words#\n",
        "  z = nltk.pos_tag(text)\n",
        "  # store #\n",
        "  nltk_pos.append(z)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-948c0fca1013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnltk_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m##for every sentence ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;31m# Tokenize sentence #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uGL7zn2kW9ug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "4eacdbc6-8e8c-4bc6-9b73-350b51b3ce7d"
      },
      "cell_type": "code",
      "source": [
        "### Extracting final pos by nltk in a list ###\n",
        "\n",
        "tmp = []\n",
        "nltk_result = []\n",
        "\n",
        "## every tagged sentence ##\n",
        "for i in tqdm(nltk_pos):\n",
        "  tmp = []\n",
        "  ## every word ##\n",
        "  for j in i:\n",
        "    ## append tag (from index 1) ##\n",
        "    tmp.append(j[1])\n",
        "  # join the tags of every sentence #\n",
        "  nltk_result.append(' '.join(tmp))\n",
        "\n",
        "### check ###\n",
        "for i in range(10):\n",
        "  print(nltk_result[i])\n",
        "  print(corpus[i])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6694a2447fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## every tagged sentence ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m## every word ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "s3WFcLIGXAOj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install flair\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6LCrqTDXER9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "50305f61-8492-420f-89e5-5209ce1d9d4e"
      },
      "cell_type": "code",
      "source": [
        "# initiating object #\n",
        "pos = SequenceTagger.load('pos-fast')\n",
        "\n",
        "#for storing pos tagged string#\n",
        "f_pos = []\n",
        "## for every sentence ##\n",
        "for i in tqdm(corpus):\n",
        "  sentence = Sentence(i)\n",
        "  pos.predict(sentence)\n",
        "  ## append tagged sentence ##\n",
        "  f_pos.append(sentence.to_tagged_string())\n",
        "\n",
        "###check ###\n",
        "for i in range(10):\n",
        "  print(f_pos[i])\n",
        "  print(corpus[i])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-cd2aecab69f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceTagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pos-fast'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#for storing pos tagged string#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## for every sentence ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SequenceTagger' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "kRmhqlvhXH33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "1f6fbe80-cd69-448e-f434-e1e805ee8101"
      },
      "cell_type": "code",
      "source": [
        "Import re\n",
        "\n",
        "### Extracting POS tags ###\n",
        "## in every sentence by index ##\n",
        "for i in tqdm(range(len(f_pos))):\n",
        "  ## for every words ith sentence ##\n",
        "  for j in corpus[i].split():\n",
        "    ## replace that word from ith sentence in f_pos ##\n",
        "    f_pos[i] = str(f_pos[i]).replace(j,\"\",1)\n",
        "\n",
        "  ## Removing < > symbols ##\n",
        "  for j in  ['<','>']:\n",
        "    f_pos[i] = str(f_pos[i]).replace(j,\"\")\n",
        "\n",
        "    ## removing redundant spaces ##\n",
        "    f_pos[i] = re.sub(' +', ' ', str(f_pos[i]))\n",
        "    f_pos[i] = str(f_pos[i]).lstrip()\n",
        "\n",
        "### check ###\n",
        "for i in range(10):\n",
        "  print(f_pos[i])\n",
        "  print(corpus[i])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-79131534ed91>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Import re\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "VxtcSCz-XMHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "82b4cb57-c9c2-4d27-aec4-aca144c0180b"
      },
      "cell_type": "code",
      "source": [
        "### Removing Symbols and redundant space ###\n",
        "\n",
        "## in every sentence by index ##\n",
        "for i in tqdm(range(len(corpus))):\n",
        "  # Removing Symbols #\n",
        "  corpus[i] = re.sub('[^a-zA-Z]', ' ', str(corpus[i]))\n",
        "  POS[i] = re.sub('[^a-zA-Z]', ' ', str(POS[i]))\n",
        "  f_pos[i] = re.sub('[^a-zA-Z]', ' ', str(f_pos[i]))\n",
        "  nltk_result[i] = re.sub('[^a-zA-Z]', ' ', str(nltk_result[i]))\n",
        "\n",
        "  ## Removing HYPH SYM (they are for symbols) ##\n",
        "  f_pos[i] = str(f_pos[i]).replace('HYPH',\"\")\n",
        "  f_pos[i] = str(f_pos[i]).replace('SYM',\"\")\n",
        "  POS[i] = str(POS[i]).replace('SYM',\"\")\n",
        "  POS[i] = str(POS[i]).replace('HYPH',\"\")\n",
        "  nltk_result[i] = str(nltk_result[i].replace('HYPH',''))\n",
        "  nltk_result[i] = str(nltk_result[i].replace('SYM',''))                     \n",
        "\n",
        "  ## Removing redundant space ##\n",
        "  POS[i] = re.sub(' +', ' ', str(POS[i]))\n",
        "  f_pos[i] = re.sub(' +', ' ', str(f_pos[i]))\n",
        "  corpus[i] = re.sub(' +', ' ', str(corpus[i]))\n",
        "  nltk_result[i] = re.sub(' +', ' ', str(nltk_result[i]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8aa28a14dd41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;31m# Removing Symbols #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^a-zA-Z]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mPOS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^a-zA-Z]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPOS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mf_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^a-zA-Z]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Lvv7jMpzXOcU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "f9ab98f0-59af-4376-d420-d8b893c1b179"
      },
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "  print('corpus   '+corpus[i])\n",
        "  print('actual   '+POS[i])\n",
        "  print('nltk     '+nltk_result[i])\n",
        "  print('flair    '+f_pos[i])\n",
        "  print('-'*50)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2e387a3d19e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpus   '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'actual   '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mPOS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nltk     '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnltk_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flair    '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mf_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "gf7Fzha2XTTd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### EVALUATION FUNCTION ###\n",
        "def eval(x,y):\n",
        "  # correct match #\n",
        "  count = 0\n",
        "  #Total comparisons made# \n",
        "  comp = 0\n",
        "  ## for every sentence index in dataset ##\n",
        "  for i in range(len(x)):\n",
        "    ## if the sentence length match ##\n",
        "    if len(x[i].split()) == len(y[i].split()):\n",
        "      ## compare each word ##\n",
        "      for j in range(len(x[i].split())):\n",
        "        if x[i][j] == y[i][j] :\n",
        "          ## Match! ##\n",
        "          count = count+1\n",
        "          comp = comp + 1\n",
        "        else:\n",
        "          comp = comp + 1\n",
        "  return (count/comp)*100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZTw0KDHUXVqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "f27d61fa-aaac-4bf9-a30f-33663905ab18"
      },
      "cell_type": "code",
      "source": [
        "print(\"nltk Score \", eval2(POS,nltk_result))\n",
        "print(\"Flair Score \", eval2(POS,f_pos))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-80b224160855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nltk Score \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPOS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnltk_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Flair Score \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPOS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eval2' is not defined"
          ]
        }
      ]
    }
  ]
}